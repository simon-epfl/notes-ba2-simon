#set text(font: "DejaVu Sans")
#show heading.where(level: 1): contents => text(size: 20pt, contents)
#show heading: contents => pad(bottom: 10pt, contents)
#set quote(block: true)
#set heading(numbering: (ignore_first, ..n) => {
  if (n.pos().len() != 0) {
    numbering("1.1.", ..n)
  }
})

#outline(indent: true, title: "SHS - Communcation B (Spring 2024)")

#pagebreak()

== La loi de Moore

=== Les promesses technoscientifiques

- du 16e si√®cle au 18e si√®cle #sym.arrow fonction de sensibilisation
- 19e si√®cle #sym.arrow fonction id√©ologique

==== Ces promesses sont toujours...

- non dystopiques
- imposent des solutions technologiques
- performatives#footnote[\#olympedegouge], le fait de formuler la promesse contribue √† la faire r√©aliser (orientent les moyens allou√©s √† la recherche & innovation)

==== ...et ont pour contraintes...

- la n√©cessit√© de nouveaut√© radicale (la promesse est la solution unique √† un probl√®me urgent)
- cr√©dibilit√© (soutient des sp√©cialistes, quitte √† inventer ces soutiens)

==== Loi de Moore en micro√©lectronique

est un mod√®le pour la fabrication de promesses technoscientifiques \
#sym.arrow.r.curve d√©finit ce qui est pensable pour l'√©volution des micro-processeurs

#box(
  stroke: 1pt + rgb(34, 102, 153), 
  width: 100%, 
  fill: rgb(34, 102, 153, 30), 
  inset: 7pt,
  text(fill : black, [
    #text(fill : rgb(34, 102, 153), 
      [*üìñ Contexte* : apparitions des premiers circuits int√©gr√©s]
    )
    #pad(top: 1pt)[- Fin 1950 $arrow$ Fairchild Seminconductor fabrique des transistors ($"#"$FDS)
    - Pour inciter d'autres acteurs √† faire le pari de l'ouverture de la soci√©t√© civile, Gordon Moore, directeur R&D chez Fairchild, publie un manifeste √©conomique
    - promesse en faveur de l'int√©gration  :
    #quote(attribution: [Moore, 1965])[
      The future of integrated electronics is the future of electronics itself...
    ]] 
]))

Seconde formulation de la loi :
#quote(attribution: [Moore, 1975], text([#strike(text("The density has increased at a rate of roughly a factor of two per year")), #text("\nThe density has increased at a rate of roughly a factor of two per two years")]))

Pour les CPU, en 2024, il est probable qu'on se d√©tache de cette loi :
- l'√©nergie est ch√®re
- co√ªts des lieux de fabrication
- la consommation change (+ d'√©conomie d'√©nergie over + de performance)

== La course aux GPU

#table(
  columns: (auto, auto),
  inset: 10pt,
  align: horizon,
  table.header(
    [*CPU*], [*GPU*],
  ),
  "Quelques coeurs: entre 2 et 64", "Plusieurs coeurs: entre 2‚Äô000 et 50‚Äô000",
  "Faible latence", "Haut d√©bit de donn√©es",
  "Bon pour le traitement en s√©rie", "Bon pour le traitement en parall√®le",
  "Peut effectuer une poign√©e d‚Äôop√©rations √† la fois", "Peut effectuer des milliers d‚Äôop√©rations √† la fois"
)

Les G.P.U. (graphical processing units) sont tr√®s efficaces pour la multiplication de matrices (donc tr√®s utiles pour l'I.A.).

=== Loi de Huang

#quote(attribution: [Jensen Huang (CEO Nvidia, leader des cartes GPU)], "Les performances des GPUs seront plus que doubl√©es chaque 2 ans", )

=== Optimisation

*Repr√©sentation des nombres :* r√©duction de la pr√©cision pour acc√©lerer les calculs. (2019, Google, gr√¢ce au brain floating point).

*Nouvelles cartes :* 
- le T.P.U. (Tensor Processing Unit) par Google (2015), con√ßu pour les r√©seaux de neurones (fonctionne avec Tensorflow)
- le L.P.U. (Language Processing Unit) par Groq
- Apple S√©rie M (syst√®me sur une unique puce SoC : CPU, GPU, m√©moire unifi√©)

et beaucoup d'autres entreprises (AWS...)

=== Etat du march√©

Nvidia domine, tensions g√©opolitiques li√©es aux semi-conducteurs.

== Les mod√®les de langue

LLM : Large Language Model

=== Recette d'un bon LLM

- bcp de param√®tres (x10 chaque ann√©e, nouvelle loi de Moore ?)
- de la puissance de calcul
- bcp (bcp) de donn√©es (seront √©puis√©es en 2026 !)

== Des booms et des hivers de l'IA

Historiquement, les technologies IA ont travers√© des phases de booms et de crises.

=== Gen√®se et 1er boom de l'IA (1940‚Äì1965)

Seconde Guerre mondiale #sym.arrow augmentation de la demande en calcul \
- Angleterre #sym.arrow d√©cryptage ("Bomb", "Coloss") \
- U.S.A. #sym.arrow calcul balistique (ENIAC)

1942 : Moore School of Electrical Engineering, pour acc√©l√©rer la production de tables de tir.

1943 : \$400k allou√©s √† la constructeur de l'ENIAC (le dispositif prend le nom de "computer") \
#sym.arrow.r.curve tr√®s innovant mais probl√®me d'architecture

1944 : nouveau projet d√©riv√© de l'ENIAC, le *EDVAC* (notament gr√¢ce √† John von Neumann).

Formalisation de l'*architecture Von-Neumann* (encore tr√®s utilis√©e aujourd'hui) :

#image("neumann.png")

Juin 1945 : Neumann publie un rapport sur EDVAC (utilise des analogies avec le cerveau pour la premi√®re fois)

1949 : 1er ordinateur BINAC (r√©f√©rence √† UNIVAC, 1951), les ordinateurs/calculateurs sortent progressivement de la recherche militaire #sym.arrow *industrie et administration*.


1956 : 1√®re appartition du terme I.A. (John McCarthy)

1960 : premier boom de l'IA dite "symbolique" \
#sym.arrow.r.curve recherche logicielle visant √† d√©crire les r√®gles de pens√©e et les exprimer sous forme de code informatique (par ex. chatbot ELIZA).

Un groupe ferm√© de chercheurs s'arroge le monopole de la d√©finition des enjeux de l'IA. \
#sym.arrow.r.curve capture l'essentiel des financements (75% de US Air France) \
#sym.arrow.r.curve conserve l'acc√®s aux grands syst√®mes informatiques

... cela conduit au premier hiver.

=== Premier hiver de l'IA (1965-1975)

#sym.arrow promesses des promoteurs de l'IA symbolique n'ont pas √©t√© tenues \
#sym.arrow √† partir de 1970, baisse des financements (notamment militaires) \
#sym.arrow accus√©s de se concentrer sur des "mondes jouets"

=== Syst√®mes experts experts et 2√®me boom (1975-1985)

Renouveau de l'IA symbolique (ordi + puissant et d√©composition des processus de raisonnement en briques √©l√©mentairs)

*Syst√®me expert :*

#image("expert.png")

1970 : syst√®me MYCIN \
#sym.arrow s√©rie de questions au m√©decin \
#sym.arrow env. 600 r√®gles \
#sym.arrow produit une liste de bact√©ries candidates

1980 : XCON pour aider √† configurer les ordinateurs

1984 : DELTA pour identifier les pannes sur les locomotives

*Limites des syst√®mes expert :*

#quote(attribution: [Edward Feigenbaum, 1983])[
  Dans les d√©cennies √† venir, nous devrons disposer de moyens plus automatiques pour remplacer ce qui est actuellement une proc√©dure tr√®s fastidieuse, longue et co√ªteuse.
]

=== Deuxi√®me hiver et travail de l'ombre

Des promesses non tenues (encore...) \
#sym.arrow probl√®me de hardware \
#sym.arrow probl√®me de maintenance des logiciels \
#sym.arrow la plupart des startups ont fait faillite

1990 : IA symbolique est si affaiblie que le terme dispara√Æt quasiment du vocabulaire de recherche.

==== Parallel Distributed Processing

1986 : √† l'√©cart de l'IA symbolique, un groupe de chercheurs travaille sur les *r√©seaux de neurones* (notamment reconnaissance des codes postaux)

notion de r√©tropropagation du gradient (ajuster les param√®tres du mod√®le en fonction des erreurs qu'il commet)

LeNet-1, reconnaissance de chiffres \
LeNet-2, reconnaissance de caract√®res (reconnaissances de ZIP codes par ex.)

=== R√©seau de neurones profonds et 3√®me boom (2005-2024)

==== Av√®nement du Deep Learning :
- puissance de calcul augmente (performances des cpu #sym.arrow.tr + GPU)
- r√©seaux de neurones + profonds

==== Num√©risation et essort d'Internet

- quantit√© de donn√©es #sym.arrow.tr
- mise en place de plateformes de crowdsourcing (pour labelliser des donn√©es)

Exemple : ImageNet (1k cat√©gories d'objets, 1.2M d'images)

2012 : reconnaissance d'objets, meilleurs performances sur ImageNet (25% #sym.arrow 16%) gr√¢ce aux *filtres de convolution*.

2015 : ResNet

#sym.arrow application d‚Äôune m√™me transformation lin√©aire sur diff√©rentes zones de l‚Äôimage \
#sym.arrow on part de petites matrices (3x3) en demandant au mod√®le de g√©n√©rer de grandes matrices (5x5) *, chaque groupe est une couche de convolution*.

Il y a plusieurs *cartes d'activation* (filtre = feature, appris √† l'entra√Ænement) √† la sortie de chaque couche.

Chaque convolution est suivie d'une *fonction d'activation* non lin√©aire.

R√©duction des cartes d‚Äôactivation par *op√©ration de pooling*.

La derni√®re couche est la couche *de classification*, qui d√©termine la sortie avec poids (appris pendant l'entra√Ænement).

== Des booms et des hivers de l'IA (II)

=== Gen√®se: memorandum de Weaver et d√©mos. publiques (1950-1965)

1949 : Weaver sugg√®re une meilleure approche (statistique et probabiliste) que celle de la traduction lin√©aire

1954 : premi√®re d√©monstration publique √† New York, traduction de russe √† anglais en public.

=== Crise: le rapport ALPAC et ses cons√©quences (1965-1990)

1966 : le rapport ALPAC (Automatic Language Processing Advisory Committee)

#quote(attribution: [National Research Council, 1966])[Il n‚Äôy a aucune urgence dans le domaine de la traduction. Le
probl√®me n‚Äôest pas de satisfaire un besoin inexistant √† travers des
syst√®mes de traduction automatiques inexistants]

peu de b√©n√©fices √† court-terme #sym.arrow *chute drastique des financements.*

=== Renouveau et tradition statistique (1990-2015)

1990 : apparition de corpus parall√®les (utiles pour la traduction)

1992 : rapport JTEC (Japan Technology Evaluation Center) et incitations politiques (convaincre les gouvernements d'utiliser les nouvelles technologies)

mais aussi puissance de calcul et stockage #sym.arrow.tr \
et nouvelle culture statistique, probabiliste

==== Focus sur mod√®les de traduction bas√©s sur les groupes de mots

1993 : IBM introduit plusieurs mod√®les statistiques pour la traduction (corpus parall√®les issus du parlement canadien)

2006 : Google Translate, bas√©e sur cette m√©thode

===== Comment √ßa marche ?

- segmentation des phrases en groupe de mots (tokens)
- recherche de correspondances les + probables
- assemblage des correspondances

===== Limitations de l‚Äôapproche statistique

- traduction fausse si syntaxe non courante
- utilisation de l'anglais comme "langue pivot" (FR #sym.arrow EN #sym.arrow IT)

=== Traduction automatique par r√©seau de neurones (2014-2024)

==== Boom des ConvNets

Entre 2012 et 2015 : boom des ConvNets pour traitement des images

===== Comment √ßa marche ?

Comment apprendre le langage naturel avec des r√©seaux de neurones?

- les machines comprennent le langage binaire
- les r√©seaux de neurones doivent recevoir en entr√©e des donn√©es continues
- le texte est repr√©sent√© par des symboles discrets (lettres, chiffres, caract√®res sp√©ciaux, etc.)

*Probl√®me :* avec ASCII, l'encodage binaire, un mot n'est pas d√©fini par ses lettres, impossibilit√© d'apprendre le sens d'un mot avec binaire. (ex chouette #sym.eq.not brouette).

*Solution :* encodage one-hot : gr√¢ce au word embeddings un graph bas√© sur le sens tous les mots va se former.

Pour cela : on prend la probabilit√© de coocurrence P(c/w), puis on r√©duit les dimensions trouv√©es pour √™tre + ou - pr√©cis dans la compr√©hension (gr√¢ce √† la SVD).

#sym.arrow une m√©thode efficace mais peu efficiente (√ßa a pris 4 mois pour s'entra√Æner sur Wikipedia).

===== word2vec (2013)

- mod√®le lin√©aire
- tricks pour am√©liorer l'apprentissage des mots rares
- code open source en C
- apprentissages de word embeddings en quelques minutes

Exemple : d√©terminer si un avis est positif ou n√©gatif.

==== R√©seaux r√©currents

- adapt√© au langage, qui est s√©quentiel

2014 : premiers r√©seaux de neurones r√©currents pour la traduction
automatique

==== Long-Short Term Memory (LSTM) Network (traduction)

Probl√®me de l'√©poque : apprentissage des r√©seaux r√©currents difficile pour les longues
s√©quences.

Une id√©e des ann√©es 90 refait surface: LSTM networks.

2016: Google Translate opte pour un mod√®le de traduction neuronal bas√© sur les LSTM

===== Limites des LSTM-RNN

- probl√®me d'optimisation
- mod√®les s√©quentiels difficilement parall√©lisables
- architecture peu efficace sur GPU
- temps d'apprentissage + long

==== Transformer: Attention Is All You Need

- 2017: nouvelle architecture bas√©e uniquement sur le m√©canisme d‚Äôattention
- efficace sur GPU (entra√Ænement + rapide)
- les RRN n'ont pas dit leur dernier mot (transformer + rapide en entra√Ænement mais gourmands en m√©moire)
- Mars 2024: Google DeepMind pr√©sente deux nouveaux mod√®les de langue bas√©s sur des RNNs

*M√©canisme d'attention :* fait attention au contexte des mots en l'entourant.

== Supervision et apprentissage automatique

=== Apprentissage supervis√©

Une fois qu'un jeu de donn√©es est disponible, les chercheurs la divise en 2 sous-ensembles :
- jeu d'entra√Ænement
- jeu d'√©valuation

==== Des avanc√©es et des limites

- biais de s√©lection des donn√©es
- biais des annotations des donn√©es
- co√ªt de l'annotation des donn√©es (contra√Æntes de temps : ex. annotation de contrats juridiques 1/4 de temps juste pour les annoter).

=== Apprentissage auto-supervis√©

Yann Le Cun ‚ÄúCake Analogy‚Äù : la grosse partie du g√¢teau est faite avec un apprentissage non supervis√©, et le gla√ßage, la cerise, est faite avec un peu d'apprentissage supervis√©.

==== Apprentissage des donn√©es d'entr√©e

- apprendre √† pr√©dire le mot d‚Äôapr√®s, ou les mots cach√©s
- GPT (Generative Pre-Trained Transformer) #sym.arrow pr√©dire le mot suivant
- apprendre des images avec des t√¢ches "pr√©textes" pr√©d√©finies (rotation, mettre en couleur)

*Apprentissage discriminatif auto-supervis√©:* utilise un signal discriminant entre les images.

==== Apprentissage contrastif

Apprendre √† d√©terminer quelles images sont similaires avec qui. \
(on donne des paires d'images positives, c'est-√†-dire d'un m√™me set, et des paires d'images n√©gatives)

Exemple : *mod√®le CLIP*, auto-supervision avec 400M de paires (image, description) collect√©es sur le web. Performances √©quivalentes √† ImageNet. Meilleures g√©n√©ralisation des donn√©es inconnues.

=== Apprentissage par instruction (objectif: alignement)

Les mod√®les bas√©s sur l'apprentissage auto sont limit√©s, ils ne savent que pr√©dire le mot suivant.

*Solution : s'aligner sur les attentes des utilisateurs* :

#box(
  stroke: 1pt + rgb(34, 102, 153), 
  width: 100%, 
  fill: rgb(34, 102, 153, 30), 
  inset: 7pt,
  text(fill : black, [
    #pad(top: 1pt)[
    Instruction: Traduit la phrase suivante en Fran√ßais. \
Observation: The cat sat on the mat. \
Label: [...pr√©dit par le mod√®le...]] 
]))

Cependant, les donn√©es annot√©es restent co√ªteuses et limit√©es. Ainsi, on peut utiliser d'autres mod√®les pr√©-entra√Æn√©s pour g√©n√©rer des instructions.

Exemple : *Alpaca dataset,* 52 instructions g√©n√©r√©es avec GPT-3.5 √† partir de 175 instructions.

*Solution am√©lior√©e : s'aligner sur les domaines sp√©cialis√©s *

Exemple : Google Med-PaLM (mod√®le sous license propri√©taire) adapt√© depuis PaLM.

*A int√©grer √† la solution : s'aligner sur les valeurs humaines*

- le web contient des donn√©es toxiques ou mensong√®res
- human in the loop : humains qui v√©rifient les donn√©es

==== Les limites de l'alignement

- Gemini image √©tait woke
- il est actuellement dans les faits impossible de sortir de la supervision
- les mod√®les d'IA qu'on utilise ont √©t√© supervis√©s avec des biais arbitraires
- la seule piste qu'on a est de rendre explicite les valeurs qui sous-tendent le process d'annotation et d'alignement
